# 使用管道(pipelining)加速Redis查询



## 请求/响应协议和RTT

Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。

这就意味着通常一个请求的执行遵循以下的步骤：

- 客户端发送查询请求到服务器，然后监听Socket，通常是阻塞模式，等待服务器应答。
- 服务器处理命令，将处理结果返回给客户端。

因此，例如下面是4个命令序列的执行情况：

- *Client*: INCR X
- *Server*: 1
- *Client*: INCR X
- *Server*: 2
- *Client*: INCR X
- *Server*: 3
- *Client*: INCR X
- *Server*: 4

客户端和服务器通过网络连接。网络链路可能速度很快（例如loopback），也可能很慢（例如两个主机之间有很多跳）。无论网络延迟快慢，从客户端传输数据到服务器，再从服务器返回应答到客户端，都需要一定的时间。

这个时间叫做往返时间（RTT，Round Trip Time），显而易见，当客户端在一次批处理中执行多次请求时（例如将多个元素添加到同一个list中，或者往数据库中写入多个keys），性能将会受到很大影响。假设RTT是250ms（网络较慢的情况），即使服务器每秒中可以处理100K个请求，我们每秒最多也只能处理四个请求。

如果使用的是loopback，RTT会短很多（比如我的主机ping 127.0.0.1只有44ms的延迟），但是如果你想一次批处理执行很多操作，这个延迟仍然很大。

幸运的是我们有办法去解决该场景的问题。



## Redis管道

请求/响应协议的服务器能够实现，即使旧的请求还未响应，还能够同时处理新的请求。这样就可以同时发送多个命令到服务器而不用一个个等待应答，然后在最后一步读取服务器的响应。

这就叫做管道（pipelining），该技术在过去几十年中被广泛应用。比如很多POP3协议的实现都支持该特性，显著的提升了从服务器下载新邮件的速度。

Redis在最早的时候就支持了管道的功能，无论你用的什么版本，都可以使用Redis管道功能。下面是使用natcat工具发送批量请求的一个示例：

```shell
$ (printf "PING\r\nPING\r\nPING\r\n"; sleep 1) | nc localhost 6379
+PONG
+PONG
+PONG
```

这里我们不需要每个调用都花费RTT的时间，这三个命令只需要一次RTT即可。

在第一个例子中，使用管道的情况下操作顺序如下：

- *Client:* INCR X
- *Client:* INCR X
- *Client:* INCR X
- *Client:* INCR X
- *Server:* 1
- *Server:* 2
- *Server:* 3
- *Server:* 4

**注意：**当客户端使用管道发送多个命令时，服务器会被强制将应答放入队列中，这将会占用内存。所以如果你需要使用管道发送大量命令，最好按照合理的数量分批次处理，例如每次发送10k个命令，然后读取应答，再继续发送10k个命令，以此类推。这种方式速度基本一样，但是额外内存的占用最多就是缓存这10k的请求的应答所占用的空间。



## 不仅仅是RTT

管道并不仅是为了减小RTT带来的延迟，实际上它大大提升了Redis服务器每秒处理的操作数。这是因为，如果不使用管道，从获取数据然后产生应答的角度看，处理每个命令成本是很低的，但是从网络IO的角度看，开销是很高的。每次请求应答都要涉及到调用`read()`和`write()`系统调用，意味着需要从用户态切换到内核态。上下文切换的成本巨大。

如果使用管道，多个命令可以只使用一次`read()`系统调用进行读取，而多个应答也只使用一次`write()`系统调用进行发送。正因为如此，服务器每秒处理的总查询数，最初是随着管道的长度增加而线性增加，最终接近不使用管道的10倍吞吐量，如下图所示：

![pipeline_iops](..\..\imgs\pipeline_iops.png)



## 真实代码示例

下面的benchmark，我们使用Ruby的Redis客户端，去测试管道的性能提升。

```rub
require 'rubygems'
require 'redis'

def bench(descr)
    start = Time.now
    yield
    puts "#{descr} #{Time.now-start} seconds"
end

def without_pipelining
    r = Redis.new
    10000.times {
        r.ping
    }
end

def with_pipelining
    r = Redis.new
    r.pipelined {
        10000.times {
            r.ping
        }
    }
end

bench("without pipelining") {
    without_pipelining
}
bench("with pipelining") {
    with_pipelining
}
```

在我的Mac OS X系统上执行上面的脚本，将会得到下面的实验结果。该测试是在loopback接口测试，管道的性能提升是最小的，因为RTT本来就很低。

```shell
without pipelining 1.185238 seconds
with pipelining 0.250783 seconds
```

正如你所见，使用管道，提升了5倍以上的性能。



## 管道 VS 脚本

大量管道的应用场景，都可以通过[Redis脚本](https://redis.io/commands/eval) (Redis版本 >= 2.6)得到更高效的处理。脚本的一个巨大优势是，具有最小的读写延迟，使得一些读、写、计算等操作都非常迅速（管道在这个场景下不起作用，因为客户端在调用写命令之前，必须先获得读命令的结果）。

有些时候应用想在管道中发送 [EVAL](https://redis.io/commands/eval) 或者[EVALSHA](https://redis.io/commands/evalsha) 命令。这是完全可以的，并且Redis通过[SCRIPT LOAD](https://redis.io/commands/script-load)命令明确支持这种情况（它保证[EVALSHA](https://redis.io/commands/evalsha)可以成功调用）。



### 附录：为什么busy loop方式在本地回环也很慢？

在看了本篇文章之后，我们可能仍然想知道，Redis客户端和服务器都在一台物理机上，使用loopback接口时，为什么执行于下面的benchmark仍然会很慢：

```
FOR-ONE-SECOND:
    Redis.SET("foo","bar")
END
```

毕竟，如果Redis进程和客户端都在同一个物理机上，不应该是通过内存拷贝直接传输消息，而没有实际的传输延迟和网络调用吗？

原因是，操作系统的进程并不是一直处于运行状态，实际是由操作系统内核调度，让某个进程运行。所以实际的情况是，例如，当benchmark被允许执行的时候，从Redis服务器读取响应（最后一次命令的），然后写入新的命令。这个命令现在在loopback接口的缓冲区中，但是服务器为了读取该命令，内核需要先调用Redis服务器进程（当前被系统调用阻塞），然后循环往复。所以实际上loopback接口仍然像网络接口调用那样有延迟，这是由于内核进程调度引起的。

busy loop的测试，一般来说是衡量网络服务器性能的最愚蠢的做法。避免这种测试方法更加明智。

